{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af41c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages.ai import AIMessage\n",
    "from botocore.config import Config\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    ToolMessage,\n",
    "    ToolCall\n",
    ")\n",
    "from langgraph.types import interrupt\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.func import entrypoint, task\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d6383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search = TavilySearch(max_results=2, topic=\"general\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c1beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = \"report\"\n",
    "\n",
    "file_toolkit = FileManagementToolkit(\n",
    "    root_dir = str(working_directory),\n",
    "    selected_tools = [\"write_file\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063394a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileManagementToolkit(root_dir='report', selected_tools=['write_file'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63c10d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WriteFileTool(root_dir='report')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28f9edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WriteFileTool(root_dir='report')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_toolkit.get_tools()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d875c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file = file_toolkit.get_tools()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5011d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TavilySearch(max_results=2, topic='general', api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None)),\n",
       " WriteFileTool(root_dir='report')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [web_search, write_file]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64658657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tavily_search\n",
      "write_file\n"
     ]
    }
   ],
   "source": [
    "print(tools[0].name)\n",
    "print(tools[1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f48d4189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tavily_search'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TavilySearch</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">max_results</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">topic</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'general'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">api_wrapper</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TavilySearchAPIWrapper</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">tavily_api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">api_base_url</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'write_file'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WriteFileTool</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">root_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'report'</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'tavily_search'\u001b[0m: \u001b[1;35mTavilySearch\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmax_results\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
       "        \u001b[33mtopic\u001b[0m=\u001b[32m'general'\u001b[0m,\n",
       "        \u001b[33mapi_wrapper\u001b[0m=\u001b[1;35mTavilySearchAPIWrapper\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtavily_api_key\u001b[0m=\u001b[1;35mSecretStr\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mapi_base_url\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'write_file'\u001b[0m: \u001b[1;35mWriteFileTool\u001b[0m\u001b[1m(\u001b[0m\u001b[33mroot_dir\u001b[0m=\u001b[32m'report'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "# 使用するツールのリスト\n",
    "tools = [web_search, write_file]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "print(tools_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07502344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'こんにちは！お手伝いできることがありましたら、お知らせください。日本語で質問やリクエストをいただければ</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">、できる限りお答えします。\\n\\n何かお調べしたいことや、ファイルに書き込みたい内容などありますか？'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'ResponseMetadata'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'RequestId'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'4a13dc49-9a16-4cd2-b63d-7d0590da8110'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'HTTPStatusCode'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'HTTPHeaders'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Sun, 16 Nov 2025 08:53:53 GMT'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content-type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'application/json'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content-length'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'612'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'connection'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'keep-alive'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'x-amzn-requestid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'4a13dc49-9a16-4cd2-b63d-7d0590da8110'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'RetryAttempts'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stopReason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'end_turn'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'metrics'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'latencyMs'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1827</span><span style=\"font-weight: bold\">]}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us.anthropic.claude-3-7-sonnet-20250219-v1:0'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run--7229f0c2-d20f-4a95-bc5b-cb9474e2c215-0'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2236</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2320</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'input_token_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'cache_creation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cache_read'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'こんにちは！お手伝いできることがありましたら、お知らせください。日本語で質問やリクエストをいただければ\u001b[0m\n",
       "\u001b[32m、できる限りお答えします。\\n\\n何かお調べしたいことや、ファイルに書き込みたい内容などありますか？'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'ResponseMetadata'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'RequestId'\u001b[0m: \u001b[32m'4a13dc49-9a16-4cd2-b63d-7d0590da8110'\u001b[0m,\n",
       "            \u001b[32m'HTTPStatusCode'\u001b[0m: \u001b[1;36m200\u001b[0m,\n",
       "            \u001b[32m'HTTPHeaders'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'date'\u001b[0m: \u001b[32m'Sun, 16 Nov 2025 08:53:53 GMT'\u001b[0m,\n",
       "                \u001b[32m'content-type'\u001b[0m: \u001b[32m'application/json'\u001b[0m,\n",
       "                \u001b[32m'content-length'\u001b[0m: \u001b[32m'612'\u001b[0m,\n",
       "                \u001b[32m'connection'\u001b[0m: \u001b[32m'keep-alive'\u001b[0m,\n",
       "                \u001b[32m'x-amzn-requestid'\u001b[0m: \u001b[32m'4a13dc49-9a16-4cd2-b63d-7d0590da8110'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'RetryAttempts'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'stopReason'\u001b[0m: \u001b[32m'end_turn'\u001b[0m,\n",
       "        \u001b[32m'metrics'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'latencyMs'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m1827\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run--7229f0c2-d20f-4a95-bc5b-cb9474e2c215-0'\u001b[0m,\n",
       "    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m2236\u001b[0m,\n",
       "        \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m84\u001b[0m,\n",
       "        \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m2320\u001b[0m,\n",
       "        \u001b[32m'input_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'cache_creation'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'cache_read'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = Config(\n",
    "    read_timeout=300,\n",
    ")\n",
    "\n",
    "llm_with_tools = init_chat_model(\n",
    "    # model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    model=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    model_provider=\"bedrock_converse\",\n",
    "    config=cfg,\n",
    ").bind_tools(tools)\n",
    "\n",
    "print(llm_with_tools.invoke(\"こんにちは\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beab0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# システムプロンプト\n",
    "system_prompt = \"\"\"\n",
    "あなたの責務はユーザからのリクエストを調査し、調査結果をファイル出力することです。\n",
    "- ユーザーのリクエスト調査にWeb検索が必要であれば、Web検索ツールを使ってください。\n",
    "- 必要な情報が集まったと判断したら検索は終了して下さい。\n",
    "- 検索は最大2回までとしてください。\n",
    "- ファイル出力はHTML形式(.html)に変換して保存してください。\n",
    "  * Web検索が拒否された場合、Web検索を中止してレポート作成してください。\n",
    "  * レポート保存を拒否された場合、レポート作成を中止し、内容をユーザーに直接伝えて下さい。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebd09ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def invoke_llm(messages: list[BaseMessage]) -> AIMessage:\n",
    "    response = llm_with_tools.invoke(\n",
    "        [SystemMessage(content=system_prompt)] + messages\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def use_tool(tool_call):\n",
    "    tool = tools_by_name[tool_call[\"name\"]]\n",
    "    observation = tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    return ToolMessage(content=observation, tool_call_id=tool_call[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fe066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_human(tool_call: ToolCall):\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    tool_args = tool_call[\"args\"]\n",
    "    tool_data = {\"name\": tool_name}\n",
    "    if tool_name == web_search.name:\n",
    "        args =  f'* ツール名\\n'\n",
    "        args += f'  * {tool_name}\\n'\n",
    "        args += \"* 引数\\n\"\n",
    "        for key, value in tool_args.items():\n",
    "            args += f'  * {key}\\n'\n",
    "            args += f'    * {value}\\n'\n",
    "\n",
    "        tool_data[\"args\"] = args\n",
    "    elif tool_name == write_file.name:\n",
    "        args =  f'* ツール名\\n'\n",
    "        args += f'  * {tool_name}\\n'\n",
    "        args += f'* 保存ファイル名\\n'\n",
    "        args += f'  * {tool_args[\"file_path\"]}'\n",
    "        tool_data[\"html\"] = tool_args[\"text\"]\n",
    "    tool_data[\"args\"] = args\n",
    "\n",
    "    feedback = interrupt(tool_data)\n",
    "    \n",
    "    if feedback == \"APPROVE\": # ユーザーがツール利用を承認したとき\n",
    "        return tool_call\n",
    "\n",
    "    # ユーザーがツール利用を承認しなかったとき(DENY)\n",
    "    return ToolMessage(\n",
    "        content=\"ツール利用が拒否されたため、処理を終了してください。\", \n",
    "        name=tool_name, \n",
    "        tool_call_id=tool_call[\"id\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = MemorySaver()\n",
    "@entrypoint(checkpointer)\n",
    "def agent(messages):\n",
    "    llm_response = invoke_llm(messages.result())\n",
    "    print(llm_response)\n",
    "\n",
    "    while True:\n",
    "        if not llm_response.tool_calls:\n",
    "            break\n",
    "\n",
    "        approve_tools = []\n",
    "        tool_results = []\n",
    "\n",
    "        for tool_call in llm_response.tool_calls:\n",
    "            feedback = ask_human(tool_call)\n",
    "\n",
    "            if isinstance(feedback, ToolMessage):\n",
    "                tool_results.append(feedback)\n",
    "            else:\n",
    "                approve_tools.append(feedback)\n",
    "\n",
    "        tool_futures = []\n",
    "        for tool_call in approve_tools:\n",
    "            future = use_tool(tool_call)\n",
    "            tool_futures.append(future)\n",
    "\n",
    "        tool_use_results = []\n",
    "        for future in tool_futures:\n",
    "            result = future.result()\n",
    "            tool_use_results.append(result)\n",
    "\n",
    "        messages = add_messages(\n",
    "            messages,\n",
    "            [llm_response, *tool_use_results, *tool_results]\n",
    "        )\n",
    "\n",
    "        llm_response = invoke_llm(messages).result()\n",
    "    \n",
    "    return llm_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95758b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb38682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チェックポインターの設定\n",
    "checkpointer = MemorySaver()\n",
    "@entrypoint(checkpointer)\n",
    "def agent(messages):\n",
    "    # LLMを呼び出し\n",
    "    llm_response = invoke_llm(messages).result()\n",
    "    \n",
    "    # ツール呼び出しがある限り繰り返す\n",
    "    while True:\n",
    "        if not llm_response.tool_calls:\n",
    "            break\n",
    "\n",
    "        approve_tools = []\n",
    "        tool_results = []\n",
    "        \n",
    "        # 各ツール呼び出しに対してユーザーの承認を求める\n",
    "        for tool_call in llm_response.tool_calls:\n",
    "            feedback = ask_human(tool_call)\n",
    "            if isinstance(feedback, ToolMessage):\n",
    "                tool_results.append(feedback)\n",
    "            else:\n",
    "                approve_tools.append(feedback)\n",
    "\n",
    "        # 承認されたツールを実行\n",
    "        tool_futures = []\n",
    "        for tool_call in approve_tools:\n",
    "            future = use_tool(tool_call)   # 非同期実行を開始\n",
    "            tool_futures.append(future)\n",
    "\n",
    "        # Future が完了するのを待って結果だけを集める\n",
    "        tool_use_results = []\n",
    "        for future in tool_futures:\n",
    "            result = future.result()       # 完了まで待ち、結果を取得\n",
    "            tool_use_results.append(result)\n",
    "\n",
    "        # メッセージリストに追加\n",
    "        messages = add_messages(\n",
    "            messages,\n",
    "            [llm_response, *tool_use_results, *tool_results]\n",
    "        )\n",
    "\n",
    "        # モデルを再度呼び出し\n",
    "        llm_response = invoke_llm(messages).result()\n",
    "    \n",
    "    # 最終結果を返す\n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d5821c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
